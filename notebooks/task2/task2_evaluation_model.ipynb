{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc3e260",
   "metadata": {},
   "source": [
    "# From task2_VGG16 and task2_mobnetv2, we have the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d794b0",
   "metadata": {},
   "source": [
    "## Model Comparison: VGG16 vs MobileNetV2 (Task 2)\n",
    "\n",
    "| Model        | Best Val Accuracy | Best Val Loss | Final Train Accuracy | Final Train Loss | Training Time per Epoch |\n",
    "|--------------|-------------------|---------------|-----------------------|------------------|--------------------------|\n",
    "| **VGG16**     | 0.9348            | 0.1995        | 0.9470                | 0.1705           | 388ms/step               |\n",
    "| **MobileNetV2** | **0.9773**      | **0.0899**    | **0.9829**            | **0.0534**       | **277ms/step**           |\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "- **Validation Performance**: MobileNetV2 clearly outperforms VGG16 with a higher validation accuracy (97.73% vs 93.48%) and a significantly lower validation loss (0.0899 vs 0.1995). This suggests that MobileNetV2 generalizes better on unseen data.\n",
    "  \n",
    "- **Training Performance**: MobileNetV2 also achieves better training accuracy and lower loss, indicating more effective learning with less overfitting.\n",
    "\n",
    "- **Training Efficiency**: MobileNetV2 trains faster per epoch (277ms/step vs 388ms/step), which is especially important for scaling up or fine-tuning on larger datasets or edge devices.\n",
    "\n",
    "### Ultimate Judgement\n",
    "\n",
    "**MobileNetV2 is the superior model** for this classification task. It not only delivers better accuracy and lower loss but also trains faster. Unless model size or deployment constraints favor VGG16, MobileNetV2 should be the go-to model for deployment and further experimentation.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
