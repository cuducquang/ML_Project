{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cuducquang/ML_Project/blob/main/task2_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Colab Link\n",
        "This cell provides a link to open the notebook in Google Colab, a cloud-based platform for running Jupyter Notebooks with GPU support. The badge ensures easy access to the notebook's environment.\n",
        "- **Purpose**: Facilitates sharing and collaboration by linking directly to the Google Colab environment.\n",
        "- **Output**: Displays a clickable badge to open the notebook in Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Keras Tuner\n",
        "This cell installs the `keras-tuner` library, which is used for hyperparameter tuning of the neural network model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmk-gsXfEmsq",
        "outputId": "3b513889-8329-4efc-8ebb-b9db44c57388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXb-c8OSCDu"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "### Import Libraries\n",
        "This cell imports all necessary Python libraries and modules required for data processing, model building, training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b33728Y_E3Lq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import hashlib\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import math\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras_tuner import HyperParameters\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD5J9GXzSIHP"
      },
      "source": [
        "## Download Training Dataset\n",
        "\n",
        "### Download Training Dataset\n",
        "This cell mounts Google Drive and downloads the training dataset (`train_images.zip`) from Google Drive using the `gdown` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jS0AXXFGmK",
        "outputId": "b67a5444-aa1b-4965-cddc-88444f5f2244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l-KlchrHmf3v87KneUe1Ejn-u9Ubfi1S\n",
            "From (redirected): https://drive.google.com/uc?id=1l-KlchrHmf3v87KneUe1Ejn-u9Ubfi1S&confirm=t&uuid=f518dc1e-2de1-48d4-b2ef-3468717b830b\n",
            "To: /content/train_images.zip\n",
            "100%|██████████| 517M/517M [00:06<00:00, 74.6MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded: /content/train_images.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Google Drive file ID (from the shared link)\n",
        "file_id = \"1l-KlchrHmf3v87KneUe1Ejn-u9Ubfi1S\"\n",
        "file_name = \"train_images.zip\"\n",
        "file_path = \"/content/\" + file_name\n",
        "\n",
        "# Download the file\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", file_path, quiet=False)\n",
        "print(f\"Downloaded: {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFaw0axtSLo9"
      },
      "source": [
        "## Unzip Training Dataset\n",
        "\n",
        "### Unzip Training Dataset\n",
        "This cell extracts the contents of the `train_images.zip` file to a specified directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HHTJZ3g5FcrT"
      },
      "outputs": [],
      "source": [
        "!unzip -q $file_path -d /content/extracted_folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbYXz_I3SOdu"
      },
      "source": [
        "## Data Augmentation for Training and Validation Datasets\n",
        "\n",
        "### Data Augmentation for Training and Validation Datasets\n",
        "This cell sets up data augmentation for the training dataset and prepares the validation dataset for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHjQH5X5FtTs",
        "outputId": "8463f4db-42b2-4a6e-a0f0-05ae75aad046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21289 images belonging to 10 classes.\n",
            "Found 2071 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = '/content/extracted_folder/train'\n",
        "val_dir = '/content/extracted_folder/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0, # 224, 224 , 3\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Purpose:\n",
        "- Training Data Augmentation: Enhances the training dataset with transformations to improve model generalization.\n",
        "- Validation Data Preparation: Normalizes validation images without augmentation.\n",
        "\n",
        "Key Components:\n",
        "- Training Directory: /content/extracted_folder/train contains training images.\n",
        "- Validation Directory: /content/extracted_folder/val contains validation images.\n",
        "\n",
        "ImageDataGenerator for Training:\n",
        "- rescale=1.0/255.0: Normalizes pixel values to [0, 1].\n",
        "- rotation_range=10: Rotates images by up to 10 degrees.\n",
        "- width_shift_range=0.05, height_shift_range=0.05: Shifts images horizontally/vertically by 5%.\n",
        "- zoom_range=0.1: Zooms in/out by 10%.\n",
        "- horizontal_flip=True: Randomly flips images horizontally.\n",
        "- brightness_range=[0.8, 1.2]: Adjusts brightness by 80% to 120%.\n",
        "- fill_mode='nearest': Fills missing pixels with the nearest value.\n",
        "\n",
        "Training Generator:\n",
        "- Loads images from train_dir.\n",
        "- Resizes images to 224x224 pixels (required by VGG16).\n",
        "- Uses a batch size of 32.\n",
        "- class_mode='categorical': One-hot encodes labels for 10 classes.\n",
        "\n",
        "Validation Generator:\n",
        "- Only rescales images (no augmentation).\n",
        "- Uses a larger batch size of 64 for efficiency.\n",
        "\n",
        "Output:\n",
        "- Found 21289 images belonging to 10 classes. (Training)\n",
        "- Found 2071 images belonging to 10 classes. (Validation)\n",
        "\n",
        "Why It Matters: Data augmentation prevents overfitting by creating varied training samples, while the validation set evaluates model performance on unmodified data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Training Generator Output\n",
        "\n",
        "### Verify Training Generator Output\n",
        "This cell checks the shape and content of a batch from the training generator to ensure correct data formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pw2i5iMGBNM",
        "outputId": "eb9330ab-9c7f-46e6-93ae-966e63662290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape y_batch: (32, 10)\n",
            "Sample y_batch[0]: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "print(\"Shape y_batch:\", y_batch.shape)\n",
        "print(\"Sample y_batch[0]:\", y_batch[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI6492DNSTkl"
      },
      "source": [
        "## Build VGG16 Architecture Model\n",
        "\n",
        "### Build VGG16 Architecture Model\n",
        "This cell defines a function to build a VGG16-based model with tunable hyperparameters and sets up hyperparameter tuning using `keras-tuner`.\n",
        "\n",
        "##### Purpose: Defines a customizable VGG16 model and sets up hyperparameter tuning to optimize its architecture.\n",
        "#### Key Components:\n",
        "    + Model Architecture:\n",
        "        + Uses VGG16 without pre-trained weights (weights=None) and without the top layers (include_top=False).\n",
        "        + Input shape is (224, 224, 3) (RGB images).\n",
        "        + Adds GlobalAveragePooling2D to reduce spatial dimensions.\n",
        "        + Dense Block 1:\n",
        "        + Dense layer with tunable units (256 to 1024, step 128).\n",
        "        + BatchNormalization for stabilizing training.\n",
        "        + ReLU activation.\n",
        "        + Dropout with tunable rate (0.2 to 0.5, step 0.1).\n",
        "        + Dense Block 2:\n",
        "        + Dense layer with tunable units (64 to 512, step 64).\n",
        "        + BatchNormalization and ReLU.\n",
        "        + Dropout with tunable rate (0.1 to 0.4, step 0.1).\n",
        "        + Output Layer: Dense layer with 10 units (for 10 rice varieties) and softmax activation.\n",
        "        + Compiled with Adam optimizer, categorical_crossentropy loss, and accuracy metric.\n",
        "    + Hyperparameters:\n",
        "        + dense1_units: Number of units in the first dense layer.\n",
        "        + dropout_rate1: Dropout rate for the first block.\n",
        "        + dense2_units: Number of units in the second dense layer.\n",
        "        + dropout_rate2: Dropout rate for the second block.\n",
        "        + learning_rate: Optimizer learning rate (0.01, 0.001, 0.0005, 0.0001).\n",
        "    + Callbacks:\n",
        "        + EarlyStopping: Stops training if val_accuracy doesn’t improve for 5 epochs, restoring the best weights.\n",
        "        + ReduceLROnPlateau: Reduces learning rate by half if val_loss doesn’t improve for 2 epochs (minimum 1e-6).\n",
        "    + Tuner:\n",
        "        + Uses BayesianOptimization to search for the best hyperparameters.\n",
        "        + Optimizes for val_accuracy over 20 trials.\n",
        "        + Stores results in kt_bayesian/rice_variety_tuning.\n",
        "    + Output: Displays the search space summary, detailing the tunable hyperparameters and their ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edmN9UrGGDeK",
        "outputId": "52c41d24-fbb4-4e7d-9c48-41fd58951fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "dense1_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 256, 'max_value': 1024, 'step': 128, 'sampling': 'linear'}\n",
            "dropout_rate1 (Float)\n",
            "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "dense2_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
            "dropout_rate2 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.4, 'step': 0.1, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0005, 0.0001], 'ordered': True}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import (BatchNormalization, Activation)\n",
        "\n",
        "def build_model(hp):\n",
        "    base_model = VGG16(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = Dense(\n",
        "        units=hp.Int('dense1_units', min_value=256, max_value=1024, step=128)\n",
        "    )(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(hp.Float('dropout_rate1', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = Dense(\n",
        "        units=hp.Int('dense2_units', min_value=64, max_value=512, step=64)\n",
        "    )(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(hp.Float('dropout_rate2', min_value=0.1, max_value=0.4, step=0.1))(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 5e-4, 1e-4])\n",
        "        ),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    directory='kt_bayesian',\n",
        "    project_name='rice_variety_tuning'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ4ARLySSYLu"
      },
      "source": [
        "## Fine-Tune Search\n",
        "\n",
        "### Fine-Tune Search\n",
        "This cell performs hyperparameter tuning using the `BayesianOptimization` tuner and retrieves the best hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQoxDplollkk",
        "outputId": "5eb4a6f9-c4d4-4d03-8fd7-6f6661752eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 6 Complete [00h 26m 31s]\n",
            "val_accuracy: 0.6735876202583313\n",
            "\n",
            "Best val_accuracy So Far: 0.9159826040267944\n",
            "Total elapsed time: 07h 16m 48s\n",
            "\n",
            "Search: Running Trial #7\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "768               |1024              |dense1_units\n",
            "0.4               |0.4               |dropout_rate1\n",
            "64                |384               |dense2_units\n",
            "0.2               |0.1               |dropout_rate2\n",
            "0.001             |0.0005            |learning_rate\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 401ms/step - accuracy: 0.3702 - loss: 1.8940 - val_accuracy: 0.6688 - val_loss: 1.2252 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.4391 - loss: 1.6446 - val_accuracy: 0.3211 - val_loss: 2.0007 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.4861 - loss: 1.4938\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 392ms/step - accuracy: 0.4861 - loss: 1.4938 - val_accuracy: 0.4621 - val_loss: 1.7281 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.5349 - loss: 1.3560 - val_accuracy: 0.7214 - val_loss: 0.9348 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.5515 - loss: 1.2878 - val_accuracy: 0.5321 - val_loss: 1.4892 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.5713 - loss: 1.2298 - val_accuracy: 0.7209 - val_loss: 0.9297 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.5955 - loss: 1.1655 - val_accuracy: 0.7204 - val_loss: 0.8996 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.6054 - loss: 1.1182 - val_accuracy: 0.7644 - val_loss: 0.7385 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 391ms/step - accuracy: 0.6328 - loss: 1.0668 - val_accuracy: 0.7228 - val_loss: 0.8611 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m370/666\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 382ms/step - accuracy: 0.6492 - loss: 1.0231"
          ]
        }
      ],
      "source": [
        "tuner.search(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Best Hyperparameters: {best_hps.values}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMjnQE1zSbnl"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "### Train Model\n",
        "This cell builds and trains the model using the best hyperparameters found from tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls_my3DuGl5z",
        "outputId": "1d30ca10-2929-4f60-82c6-7eefff82d291"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 455ms/step - accuracy: 0.3656 - loss: 1.9056 - val_accuracy: 0.4128 - val_loss: 1.7877 - learning_rate: 5.0000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 383ms/step - accuracy: 0.4716 - loss: 1.5496 - val_accuracy: 0.5031 - val_loss: 1.5178 - learning_rate: 5.0000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 389ms/step - accuracy: 0.5075 - loss: 1.4357 - val_accuracy: 0.6803 - val_loss: 1.1118 - learning_rate: 5.0000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 386ms/step - accuracy: 0.5362 - loss: 1.3436 - val_accuracy: 0.5983 - val_loss: 1.1837 - learning_rate: 5.0000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 388ms/step - accuracy: 0.5545 - loss: 1.2710 - val_accuracy: 0.7117 - val_loss: 0.8887 - learning_rate: 5.0000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.5873 - loss: 1.1672 - val_accuracy: 0.7141 - val_loss: 0.9397 - learning_rate: 5.0000e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.6256 - loss: 1.0595 - val_accuracy: 0.7093 - val_loss: 0.8632 - learning_rate: 5.0000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.6548 - loss: 0.9678 - val_accuracy: 0.7349 - val_loss: 0.8046 - learning_rate: 5.0000e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 390ms/step - accuracy: 0.7031 - loss: 0.8454 - val_accuracy: 0.7620 - val_loss: 0.7119 - learning_rate: 5.0000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 385ms/step - accuracy: 0.7265 - loss: 0.7888 - val_accuracy: 0.7779 - val_loss: 0.6487 - learning_rate: 5.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 390ms/step - accuracy: 0.7562 - loss: 0.7035 - val_accuracy: 0.7238 - val_loss: 0.7596 - learning_rate: 5.0000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.7860 - loss: 0.6212\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.7860 - loss: 0.6212 - val_accuracy: 0.7595 - val_loss: 0.6740 - learning_rate: 5.0000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 391ms/step - accuracy: 0.8236 - loss: 0.5051 - val_accuracy: 0.8624 - val_loss: 0.4247 - learning_rate: 2.5000e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.8547 - loss: 0.4306 - val_accuracy: 0.8870 - val_loss: 0.3305 - learning_rate: 2.5000e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 386ms/step - accuracy: 0.8615 - loss: 0.3955 - val_accuracy: 0.9087 - val_loss: 0.2901 - learning_rate: 2.5000e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 393ms/step - accuracy: 0.8732 - loss: 0.3665 - val_accuracy: 0.8865 - val_loss: 0.3454 - learning_rate: 2.5000e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8860 - loss: 0.3295\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.8860 - loss: 0.3295 - val_accuracy: 0.7856 - val_loss: 0.7228 - learning_rate: 2.5000e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.9084 - loss: 0.2766 - val_accuracy: 0.9218 - val_loss: 0.2452 - learning_rate: 1.2500e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.9157 - loss: 0.2524 - val_accuracy: 0.9034 - val_loss: 0.2924 - learning_rate: 1.2500e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 386ms/step - accuracy: 0.9178 - loss: 0.2456 - val_accuracy: 0.9179 - val_loss: 0.2340 - learning_rate: 1.2500e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.9232 - loss: 0.2228 - val_accuracy: 0.8904 - val_loss: 0.3047 - learning_rate: 1.2500e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.9285 - loss: 0.2033 - val_accuracy: 0.9367 - val_loss: 0.1992 - learning_rate: 1.2500e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.9297 - loss: 0.2062 - val_accuracy: 0.9155 - val_loss: 0.2290 - learning_rate: 1.2500e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.9316 - loss: 0.1996\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 386ms/step - accuracy: 0.9316 - loss: 0.1995 - val_accuracy: 0.9116 - val_loss: 0.2403 - learning_rate: 1.2500e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.9470 - loss: 0.1705 - val_accuracy: 0.9348 - val_loss: 0.1995 - learning_rate: 6.2500e-05\n",
            "Restoring model weights from the end of the best epoch: 22.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "best_hps = HyperParameters()\n",
        "best_hps.Fixed('dense1_units', 1024)\n",
        "best_hps.Fixed('dropout_rate1', 0.4)\n",
        "best_hps.Fixed('dense2_units', 384)\n",
        "best_hps.Fixed('dropout_rate2', 0.1)\n",
        "best_hps.Fixed('learning_rate', 0.0005)\n",
        "\n",
        "# Build and train the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "best_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=25,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "best_model.save(\"best_rice_variety_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPh9mPmK+/N7xyrYDwrEUvo",
      "gpuType": "L4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
