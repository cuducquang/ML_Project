{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cuducquang/ML_Project/blob/main/task2_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmk-gsXfEmsq",
        "outputId": "3b513889-8329-4efc-8ebb-b9db44c57388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "jTXb-c8OSCDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b33728Y_E3Lq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import hashlib\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import math\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras_tuner import HyperParameters\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download TrainDataset"
      ],
      "metadata": {
        "id": "hD5J9GXzSIHP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jS0AXXFGmK",
        "outputId": "b67a5444-aa1b-4965-cddc-88444f5f2244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l-KlchrHmf3v87KneUe1Ejn-u9Ubfi1S\n",
            "From (redirected): https://drive.google.com/uc?id=1l-KlchrHmf3v87KneUe1Ejn-u9Ubfi1S&confirm=t&uuid=f518dc1e-2de1-48d4-b2ef-3468717b830b\n",
            "To: /content/train_images.zip\n",
            "100%|██████████| 517M/517M [00:06<00:00, 74.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: /content/train_images.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Google Drive file ID (from the shared link)\n",
        "file_id = \"1l-KlchrHmf3v87KneUe1Ejn-u9Ubfi1S\"\n",
        "file_name = \"train_images.zip\"\n",
        "file_path = \"/content/\" + file_name\n",
        "\n",
        "# Download the file\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", file_path, quiet=False)\n",
        "print(f\"Downloaded: {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unzip TrainDataset"
      ],
      "metadata": {
        "id": "CFaw0axtSLo9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HHTJZ3g5FcrT"
      },
      "outputs": [],
      "source": [
        "!unzip -q $file_path -d /content/extracted_folder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Argumentation for Train & Val Dataset"
      ],
      "metadata": {
        "id": "xbYXz_I3SOdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHjQH5X5FtTs",
        "outputId": "8463f4db-42b2-4a6e-a0f0-05ae75aad046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21289 images belonging to 10 classes.\n",
            "Found 2071 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = '/content/extracted_folder/train'\n",
        "val_dir = '/content/extracted_folder/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0, # 224, 224 , 3\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pw2i5iMGBNM",
        "outputId": "eb9330ab-9c7f-46e6-93ae-966e63662290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape y_batch: (32, 10)\n",
            "Sample y_batch[0]: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "print(\"Shape y_batch:\", y_batch.shape)\n",
        "print(\"Sample y_batch[0]:\", y_batch[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build VGG16 architecture model"
      ],
      "metadata": {
        "id": "SI6492DNSTkl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edmN9UrGGDeK",
        "outputId": "52c41d24-fbb4-4e7d-9c48-41fd58951fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "dense1_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 256, 'max_value': 1024, 'step': 128, 'sampling': 'linear'}\n",
            "dropout_rate1 (Float)\n",
            "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "dense2_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
            "dropout_rate2 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.4, 'step': 0.1, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0005, 0.0001], 'ordered': True}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import (BatchNormalization, Activation)\n",
        "\n",
        "def build_model(hp):\n",
        "    base_model = VGG16(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = Dense(\n",
        "        units=hp.Int('dense1_units', min_value=256, max_value=1024, step=128)\n",
        "    )(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(hp.Float('dropout_rate1', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
        "\n",
        "    # Dense Block 2\n",
        "    x = Dense(\n",
        "        units=hp.Int('dense2_units', min_value=64, max_value=512, step=64)\n",
        "    )(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(hp.Float('dropout_rate2', min_value=0.1, max_value=0.4, step=0.1))(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 5e-4, 1e-4])\n",
        "        ),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    directory='kt_bayesian',\n",
        "    project_name='rice_variety_tuning'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tune Search"
      ],
      "metadata": {
        "id": "xZ4ARLySSYLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQoxDplollkk",
        "outputId": "5eb4a6f9-c4d4-4d03-8fd7-6f6661752eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 6 Complete [00h 26m 31s]\n",
            "val_accuracy: 0.6735876202583313\n",
            "\n",
            "Best val_accuracy So Far: 0.9159826040267944\n",
            "Total elapsed time: 07h 16m 48s\n",
            "\n",
            "Search: Running Trial #7\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "768               |1024              |dense1_units\n",
            "0.4               |0.4               |dropout_rate1\n",
            "64                |384               |dense2_units\n",
            "0.2               |0.1               |dropout_rate2\n",
            "0.001             |0.0005            |learning_rate\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 401ms/step - accuracy: 0.3702 - loss: 1.8940 - val_accuracy: 0.6688 - val_loss: 1.2252 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.4391 - loss: 1.6446 - val_accuracy: 0.3211 - val_loss: 2.0007 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.4861 - loss: 1.4938\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 392ms/step - accuracy: 0.4861 - loss: 1.4938 - val_accuracy: 0.4621 - val_loss: 1.7281 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.5349 - loss: 1.3560 - val_accuracy: 0.7214 - val_loss: 0.9348 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.5515 - loss: 1.2878 - val_accuracy: 0.5321 - val_loss: 1.4892 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.5713 - loss: 1.2298 - val_accuracy: 0.7209 - val_loss: 0.9297 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.5955 - loss: 1.1655 - val_accuracy: 0.7204 - val_loss: 0.8996 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.6054 - loss: 1.1182 - val_accuracy: 0.7644 - val_loss: 0.7385 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 391ms/step - accuracy: 0.6328 - loss: 1.0668 - val_accuracy: 0.7228 - val_loss: 0.8611 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m370/666\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 382ms/step - accuracy: 0.6492 - loss: 1.0231"
          ]
        }
      ],
      "source": [
        "tuner.search(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Best Hyperparameters: {best_hps.values}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "iMjnQE1zSbnl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls_my3DuGl5z",
        "outputId": "1d30ca10-2929-4f60-82c6-7eefff82d291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 455ms/step - accuracy: 0.3656 - loss: 1.9056 - val_accuracy: 0.4128 - val_loss: 1.7877 - learning_rate: 5.0000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 383ms/step - accuracy: 0.4716 - loss: 1.5496 - val_accuracy: 0.5031 - val_loss: 1.5178 - learning_rate: 5.0000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 389ms/step - accuracy: 0.5075 - loss: 1.4357 - val_accuracy: 0.6803 - val_loss: 1.1118 - learning_rate: 5.0000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 386ms/step - accuracy: 0.5362 - loss: 1.3436 - val_accuracy: 0.5983 - val_loss: 1.1837 - learning_rate: 5.0000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 388ms/step - accuracy: 0.5545 - loss: 1.2710 - val_accuracy: 0.7117 - val_loss: 0.8887 - learning_rate: 5.0000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.5873 - loss: 1.1672 - val_accuracy: 0.7141 - val_loss: 0.9397 - learning_rate: 5.0000e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.6256 - loss: 1.0595 - val_accuracy: 0.7093 - val_loss: 0.8632 - learning_rate: 5.0000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 391ms/step - accuracy: 0.6548 - loss: 0.9678 - val_accuracy: 0.7349 - val_loss: 0.8046 - learning_rate: 5.0000e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 390ms/step - accuracy: 0.7031 - loss: 0.8454 - val_accuracy: 0.7620 - val_loss: 0.7119 - learning_rate: 5.0000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 385ms/step - accuracy: 0.7265 - loss: 0.7888 - val_accuracy: 0.7779 - val_loss: 0.6487 - learning_rate: 5.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 390ms/step - accuracy: 0.7562 - loss: 0.7035 - val_accuracy: 0.7238 - val_loss: 0.7596 - learning_rate: 5.0000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.7860 - loss: 0.6212\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.7860 - loss: 0.6212 - val_accuracy: 0.7595 - val_loss: 0.6740 - learning_rate: 5.0000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 391ms/step - accuracy: 0.8236 - loss: 0.5051 - val_accuracy: 0.8624 - val_loss: 0.4247 - learning_rate: 2.5000e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.8547 - loss: 0.4306 - val_accuracy: 0.8870 - val_loss: 0.3305 - learning_rate: 2.5000e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 386ms/step - accuracy: 0.8615 - loss: 0.3955 - val_accuracy: 0.9087 - val_loss: 0.2901 - learning_rate: 2.5000e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 393ms/step - accuracy: 0.8732 - loss: 0.3665 - val_accuracy: 0.8865 - val_loss: 0.3454 - learning_rate: 2.5000e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8860 - loss: 0.3295\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.8860 - loss: 0.3295 - val_accuracy: 0.7856 - val_loss: 0.7228 - learning_rate: 2.5000e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.9084 - loss: 0.2766 - val_accuracy: 0.9218 - val_loss: 0.2452 - learning_rate: 1.2500e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 387ms/step - accuracy: 0.9157 - loss: 0.2524 - val_accuracy: 0.9034 - val_loss: 0.2924 - learning_rate: 1.2500e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 386ms/step - accuracy: 0.9178 - loss: 0.2456 - val_accuracy: 0.9179 - val_loss: 0.2340 - learning_rate: 1.2500e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.9232 - loss: 0.2228 - val_accuracy: 0.8904 - val_loss: 0.3047 - learning_rate: 1.2500e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 389ms/step - accuracy: 0.9285 - loss: 0.2033 - val_accuracy: 0.9367 - val_loss: 0.1992 - learning_rate: 1.2500e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.9297 - loss: 0.2062 - val_accuracy: 0.9155 - val_loss: 0.2290 - learning_rate: 1.2500e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.9316 - loss: 0.1996\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 386ms/step - accuracy: 0.9316 - loss: 0.1995 - val_accuracy: 0.9116 - val_loss: 0.2403 - learning_rate: 1.2500e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 388ms/step - accuracy: 0.9470 - loss: 0.1705 - val_accuracy: 0.9348 - val_loss: 0.1995 - learning_rate: 6.2500e-05\n",
            "Restoring model weights from the end of the best epoch: 22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "best_hps = HyperParameters()\n",
        "best_hps.Fixed('dense1_units', 1024)\n",
        "best_hps.Fixed('dropout_rate1', 0.4)\n",
        "best_hps.Fixed('dense2_units', 384)\n",
        "best_hps.Fixed('dropout_rate2', 0.1)\n",
        "best_hps.Fixed('learning_rate', 0.0005)\n",
        "\n",
        "# Build and train the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "best_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=25,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "best_model.save(\"best_rice_variety_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load TestDataset"
      ],
      "metadata": {
        "id": "weVgGOg5Sed1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive file ID (from the shared link)\n",
        "file_test_id = \"1othgf5BTO_sZYXBOWykn2OkitSCna7J6\"\n",
        "file_test_name = \"test_images.zip\"\n",
        "file_test_path = \"/content/\" + file_test_name\n",
        "\n",
        "# Download the file\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_test_id}\", file_test_path, quiet=False)\n",
        "print(f\"Downloaded: {file_test_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwaxRp6FRdD_",
        "outputId": "8c6a6399-60ec-4a49-a6db-4b2fa976592e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1othgf5BTO_sZYXBOWykn2OkitSCna7J6\n",
            "From (redirected): https://drive.google.com/uc?id=1othgf5BTO_sZYXBOWykn2OkitSCna7J6&confirm=t&uuid=8b5ef193-2a05-4c3e-8838-5e1a8ece2f34\n",
            "To: /content/test_images.zip\n",
            "100%|██████████| 274M/274M [00:06<00:00, 42.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: /content/test_images.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unzip TestDataset"
      ],
      "metadata": {
        "id": "U7wGeMf1Sgde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q $file_test_path -d /content/extracted_test_folder"
      ],
      "metadata": {
        "id": "Uc0XIE2oRjrN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQn64OtCRsl-",
        "outputId": "24ac4136-bf50-4477-eb19-b7a449b3931e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ADT45': 0, 'AndraPonni': 1, 'AtchayaPonni': 2, 'IR20': 3, 'KarnatakaPonni': 4, 'Onthanel': 5, 'Ponni': 6, 'RR': 7, 'Surya': 8, 'Zonal': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predict on TestDataset"
      ],
      "metadata": {
        "id": "Wu77y1VQSkLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "model = load_model(\"/content/best_rice_variety_model.h5\")\n",
        "\n",
        "def predict_folder_to_csv(model, test_folder, output_csv_path, class_names):\n",
        "    results = []\n",
        "\n",
        "    for img_name in os.listdir(test_folder):\n",
        "        if img_name.lower().endswith(('.jpg')):\n",
        "            img_path = os.path.join(test_folder, img_name)\n",
        "\n",
        "            img = image.load_img(img_path, target_size=(224, 224))\n",
        "            img_array = image.img_to_array(img) / 255.0\n",
        "            img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            pred = model.predict(img_batch, verbose=0)\n",
        "            predicted_index = np.argmax(pred)\n",
        "            predicted_label = class_names[predicted_index]\n",
        "\n",
        "            results.append({\n",
        "                'filename': img_name,\n",
        "                'predicted_label': predicted_label\n",
        "            })\n",
        "\n",
        "    results = sorted(results, key=lambda x: int(x['filename'].split('.')[0]))\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\" Prediction results saved to {output_csv_path}\")\n",
        "\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "predict_folder_to_csv(\n",
        "    model=model,\n",
        "    test_folder=\"/content/extracted_test_folder/test_images\",\n",
        "    output_csv_path=\"/content/predicted_results.csv\",\n",
        "    class_names=class_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMh1vnYLRxzl",
        "outputId": "e34921bf-5080-44c4-9864-8cb9e059f099"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Prediction results saved to /content/predicted_results.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPh9mPmK+/N7xyrYDwrEUvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}